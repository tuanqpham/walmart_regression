{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "75706b49-0505-4ded-8f14-f9db95ee1c63",
      "metadata": {},
      "source": "## Factors Affecting Weekly Walmart Sales :D\n__Created by: Tuan Quang (Finn) Pham, Saniya Nadeem__\n### A. Introduction:\n- An article by Zach Lazzari (2018) that discusses the role of sales in business firms,  argues that sales is the most crucial element for the survival of an organization. Furthermore, it has a significant impact on other aspects of a business such as the firm's overall profit, brand image and most importantly, it reflects customers' perceptions of the organization. \n\n- In this project, we will be focusing on the weekly sales conditions of Walmart - a global corporation known for its extensive network of stores and diverse products. Specifically, we plan to assess several external factors we believe will have an impact on the number of sales of a company. \n\n- Throughout this analysis, we hope to aid organizations in making informed decisions and optimizing business operations. From our perspective, with a predictive model of high accuracy level, Walmart will be able to proactively respond to market dynamics, mitigate risks, and capitalize emerging opportunities. Walmart can also use this to improves \ninventory management, optimize staffing levels, tailor promotional strategies, and enhance overall efficiency. This will help the firm maintain a competitive edge in the retail industry and can also help the firm maximize its profits. \n\n### B. Methods and Plans:\n- __Research question of interest__: What is the weekly sales of Walmart based on the economics conditions and other events that are presented throughout the week?\n- __How will we answer our requestion__: We are aiming to build two different regression models: __multiple regression__, __LASSO regression__ and __Random Forest__. We will later on compare these three models by looking at the __Mean Squared Error__ (which indicates how far off our prediction is from the actual values) and finalize the best model at the end of this report. \n- __The dataset__: Our dataset was published by M. Yasser H. on Kaggle, we present a short glimpse of our dataset below.\n- __Variables in use__: We will be using `Holiday_Flag`, `Temperature`, `Fuel Price`, `CPI` and `Unemployment` as our explanatory variables, to help us analyze our sales.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8dab398a-2f22-4798-9d42-1a420e3167e2",
      "metadata": {
        "tags": [],
        "noteable": {
          "output_collection_id": "e93f590c-81dd-4d7b-a953-289532073dd2"
        },
        "ExecuteTime": {
          "end_time": "2023-09-02T19:06:26.974746+00:00",
          "start_time": "2023-09-02T19:06:26.280203+00:00"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math \n",
        "import seaborn as sns\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split, cross_validate\n",
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "debd960e-c060-45a0-bf4d-9631de7d5527",
      "metadata": {
        "tags": [],
        "noteable": {
          "output_collection_id": "bd6bcbc5-5dd7-47e3-954a-9314be680e87"
        },
        "ExecuteTime": {
          "end_time": "2023-09-02T19:06:27.329084+00:00",
          "start_time": "2023-09-02T19:06:26.980059+00:00"
        },
        "datalink": {
          "397a4e81-38d1-48ec-ac86-49b054c4ecec": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": true,
              "orig_num_cols": 8,
              "orig_num_rows": 5,
              "orig_size_bytes": 360,
              "truncated_num_cols": 8,
              "truncated_num_rows": 5,
              "truncated_size_bytes": 360,
              "truncated_string_columns": []
            },
            "display_id": "397a4e81-38d1-48ec-ac86-49b054c4ecec",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-09-02T19:06:27.166005",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_bf39f16f5f574c2cb599253e63a2726a"
          }
        }
      },
      "outputs": [],
      "source": [
        "walmart_dt = pd.read_csv(\"https://raw.githubusercontent.com/tuanqpham/toy_ds_project/main/Walmart.csv\")\n",
        "walmart_dt.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eac0b2fe-4014-45e7-b6e7-6a91efe43b6c",
      "metadata": {
        "tags": []
      },
      "source": [
        "- An explanation of the variables (as provided by the onwer of the dataset):\n",
        "    * `Store`: the store number (encoded as type integers in the dataset).\n",
        "    * `Date`: the of sales in record.\n",
        "    * `Weekly_Sales`: the number of sales in that week.\n",
        "    * `Holiday_Flag`: indicates whether the week was a special holiday (1 = Holiday Week, 0 = Non-holiday week)\n",
        "    * `Temperature`: temperature recorded in the week (in Farenheit).\n",
        "    * `Fuel_Price`: cost of fuel in the region.\n",
        "    * `Unemployment rate`: the unemployment rate\n",
        "    * `CPI`: the Consumer Price Index."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26456ba3-b987-41b5-9beb-d70de1ea30ef",
      "metadata": {},
      "source": [
        "### C. Assessing our data:\n",
        "- In this section, we will be cleaning our dataset by only keeping variables we believe are necessary in building our model. We will also be creating visualizations to gain a better understanding of the relationships between the variables: \n",
        "- Luckily for us, all column names are readable for the audience which means that there is no need for renaming these variables.\n",
        "#### C.1. Data cleaning:\n",
        "- It is important that we remove the rows and columns that are unnecessary for our analysis.\n",
        "- First. we begin by only dropping unnecessary columns for our analysis. In our case, we will be dropping the store number column as it does not directly affect our sales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e90e1d9d-50b0-4f10-9f39-d91eb3281acb",
      "metadata": {
        "tags": [],
        "noteable": {
          "output_collection_id": "5dd41cdb-2238-4681-85f8-e776c760d680"
        },
        "ExecuteTime": {
          "end_time": "2023-09-02T19:06:27.553889+00:00",
          "start_time": "2023-09-02T19:06:27.334793+00:00"
        },
        "datalink": {
          "4fac83c1-8558-43b7-919b-05b71db803ee": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": true,
              "orig_num_cols": 7,
              "orig_num_rows": 5,
              "orig_size_bytes": 320,
              "truncated_num_cols": 7,
              "truncated_num_rows": 5,
              "truncated_size_bytes": 320,
              "truncated_string_columns": []
            },
            "display_id": "4fac83c1-8558-43b7-919b-05b71db803ee",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-09-02T19:06:27.394160",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_3044b2163c1b4c2eb80164068226ec50"
          }
        }
      },
      "outputs": [],
      "source": [
        "walmart_dt_drop = walmart_dt.drop([\"Store\"], axis = 1)\n",
        "walmart_dt_drop.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "444f32d1-a889-4a20-b689-bf8a58022e43",
      "metadata": {
        "tags": [],
        "noteable": {
          "output_collection_id": "b9d11ce6-6883-4fc2-9d71-e3c0ef18b066"
        },
        "ExecuteTime": {
          "end_time": "2023-09-02T19:06:27.715937+00:00",
          "start_time": "2023-09-02T19:06:27.560688+00:00"
        }
      },
      "outputs": [],
      "source": [
        "print(walmart_dt_drop.shape)\n",
        "walmart_dt_new = walmart_dt_drop.dropna()\n",
        "print(walmart_dt_new.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70c9e900-7f8e-4669-b4a7-22cd24cba5f6",
      "metadata": {},
      "source": [
        "Fortunately, our dataset does not contain any missing values. However, we believe it is quite rare in practice to obtain datasets with no missing values."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "492bcf96-ef72-403f-8217-dd0db6733311",
      "metadata": {},
      "source": [
        "- In the next step, based on our statistical intuition, we also plan to eliminate any outliers in our data as they negatively affect the accuracy level of our regression model.\n",
        "- To do this we will first be creating a histogram plot visualizing the distribution of Weekly Sales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a0c89929-a252-4a5b-91c3-84c8c2e5d196",
      "metadata": {
        "tags": [],
        "noteable": {
          "output_collection_id": "5cb1fbe0-5f80-43a7-8393-bcbe47b443b6"
        },
        "ExecuteTime": {
          "end_time": "2023-09-02T19:06:28.209194+00:00",
          "start_time": "2023-09-02T19:06:27.721502+00:00"
        }
      },
      "outputs": [],
      "source": [
        "sns.boxplot(data = walmart_dt_new, x = \"Weekly_Sales\").set(title = \"Distribution of Weekly Sales\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a81d82b-2f07-430e-8776-83b1a703c698",
      "metadata": {},
      "source": [
        "From this boxplot, we notice that there are signs of outliers (extreme values outside the normal range) in our dataset. Therefore, we decide to eliminate them in the following step:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "bcdba6ee-68ac-49cf-8217-088da084a784",
      "metadata": {
        "tags": [],
        "noteable": {
          "output_collection_id": "da9fda94-7003-4cb6-833b-85ad94dca119"
        },
        "ExecuteTime": {
          "end_time": "2023-09-02T19:06:29.568619+00:00",
          "start_time": "2023-09-02T19:06:29.407059+00:00"
        }
      },
      "outputs": [],
      "source": [
        "#Finding the upper and lower bound of Weekly_Sales\n",
        "lower = walmart_dt_new[\"Weekly_Sales\"].quantile(0.25)\n",
        "print(lower)\n",
        "upper = walmart_dt_new[\"Weekly_Sales\"].quantile(0.75)\n",
        "print(upper)\n",
        "iqr = upper - lower\n",
        "\n",
        "max_bound = upper + (1.5*iqr)\n",
        "min_bound = lower - (1.5*iqr)\n",
        "\n",
        "# Setting all the values of Weekly Sales outside of desirable range into missing values.\n",
        "walmart_dt_new.loc[walmart_dt_new[\"Weekly_Sales\"] > max_bound, \"Weekly_Sales\"] = np.nan\n",
        "walmart_dt_new.loc[walmart_dt_new[\"Weekly_Sales\"] < min_bound, \"Weekly_Sales\"] = np.nan\n",
        "\n",
        "#Dropping missing values and reset the index\n",
        "walmart = walmart_dt_new.dropna()\n",
        "walmart = walmart.reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcd9f5d6-5091-4bc8-9403-59f790a8953f",
      "metadata": {},
      "source": [
        "#### C.2: New variable creation:\n",
        "- For our analysis, we decided to build regression models with the log of `Weekly_Sales` as the target value rather than using the original value. This is done as the relationship between our weekly sales and other predictor variables are not always linear and using the log allows for a linear relationship.\n",
        "- Furthermore, using the log allows us to achieve a more constant variance, which makes the data more suitable for regression analysis and makes it easier to interpret."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "72f34487-e204-4693-8517-e263c1f90879",
      "metadata": {
        "tags": [],
        "noteable": {
          "output_collection_id": "6c0e1446-068b-4c77-9467-8415ed21ee3c"
        },
        "ExecuteTime": {
          "end_time": "2023-09-02T19:06:30.038764+00:00",
          "start_time": "2023-09-02T19:06:29.573339+00:00"
        },
        "datalink": {
          "b47fd8dc-eb35-4bf6-b6c7-adbf23c13dce": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": true,
              "orig_num_cols": 9,
              "orig_num_rows": 6401,
              "orig_size_bytes": 512080,
              "truncated_num_cols": 9,
              "truncated_num_rows": 6401,
              "truncated_size_bytes": 512080,
              "truncated_string_columns": []
            },
            "display_id": "b47fd8dc-eb35-4bf6-b6c7-adbf23c13dce",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-09-02T19:06:29.852037",
            "user_variable_name": "walmart",
            "variable_name": "walmart"
          }
        }
      },
      "outputs": [],
      "source": [
        "walmart[\"Log_WeeklySales\"] = np.log(walmart[\"Weekly_Sales\"])\n",
        "walmart"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "040e8586-cea7-4e99-86c5-711b1c547877",
      "metadata": {},
      "source": [
        "### D. Building and evaluating our regression models:\n",
        "#### D.1. Training and Testing Data splitting:\n",
        "- As we notice in one of our predictors, the variable `Holiday_Flag` is actually a dummy variable. Therefore, when splitting our dataset into training and splitting data’s, we want to ensure that both sets contain the same proportion of weeks recorded as holidays and non-holidays.\n",
        "- We will be keeping 75% of the data for our training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "31d94670-c318-470c-bcb0-565958e3567a",
      "metadata": {
        "tags": [],
        "noteable": {
          "output_collection_id": "a15fef1b-7f4a-41ea-ae07-ffbc43ce37ed"
        },
        "ExecuteTime": {
          "end_time": "2023-09-02T19:06:30.609977+00:00",
          "start_time": "2023-09-02T19:06:30.450629+00:00"
        }
      },
      "outputs": [],
      "source": [
        "#Splitting the dataset:\n",
        "holiday = walmart.loc[walmart[\"Holiday_Flag\"] == 1]\n",
        "non_holiday = walmart.loc[walmart[\"Holiday_Flag\"] == 0]\n",
        "\n",
        "holiday_train, holiday_test = train_test_split(holiday, test_size = 0.25, random_state = 10)\n",
        "non_holiday_train, non_holiday_test = train_test_split(non_holiday, test_size = 0.25, random_state = 10)\n",
        "\n",
        "training_data = pd.concat([holiday_train, non_holiday_train])\n",
        "testing_data = pd.concat([holiday_test, non_holiday_test])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2f22325-c8ff-4996-8ecf-f1f92a27d9c5",
      "metadata": {},
      "source": [
        "#### D.2. Visualizations:\n",
        "- As mentioned above, in this subsection, we will be creating visualizations to have a better understanding of the relationships between the variables. Furthermore, we can check whether our explanatory variables do a good job at predicting the log of weekly sales!\n",
        "- First, we created boxplots illustrating the log weekly sales in holiday and non-holiday weeks to evaluate whether holiday status makes a difference in weekly market sales.\n",
        "- By comparing the boxplots, we can visually assess whether there is a noticeable difference in the distribution of log weekly sales between holiday and non-holiday weeks. If the boxplots display distinct characteristics, such as different medians or wider/narrower ranges, it suggests that the holiday status variable may have a significant influence on market sales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bd43bde5-6c21-465e-8fd2-717bd54e1b9f",
      "metadata": {
        "tags": [],
        "noteable": {
          "output_collection_id": "9d0d8fd8-dad7-49ee-b878-2952bd843cf0"
        },
        "ExecuteTime": {
          "end_time": "2023-09-02T19:06:31.020248+00:00",
          "start_time": "2023-09-02T19:06:30.618902+00:00"
        }
      },
      "outputs": [],
      "source": [
        "sns.boxplot(data = training_data, y = \"Log_WeeklySales\", x = \"Holiday_Flag\").set(title = \"Log Weekly Sales during Non-Holiday Weeks and Holiday Weeks\")\n",
        "plt.legend(labels=[\"Non-Holiday\", \"Holiday\"],\n",
        "           handles=[plt.Line2D([], [], color='blue'), plt.Line2D([], [], color='orange')])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b9e7276-587d-4b16-9679-de6e70a8cc4e",
      "metadata": {},
      "source": [
        "From the boxplots displayed above, we can see that the log weekly sales during holiday weeks is slightly higher than that during non-holiday weeks. However, given that this difference is not quite significant, we believe it is not the best predictor variable for our model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99fa20cb-14aa-4039-b332-3349b2a155b5",
      "metadata": {},
      "source": [
        "- For our quantitative variables, we will first obtain their descriptive statistics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "fe6654fc-31db-47fd-86ae-5385ce1230f9",
      "metadata": {
        "tags": [],
        "noteable": {
          "output_collection_id": "3f17f1e1-edb0-4f98-9dca-699e234d8eb1"
        },
        "ExecuteTime": {
          "end_time": "2023-09-02T19:06:31.484169+00:00",
          "start_time": "2023-09-02T19:06:31.132734+00:00"
        },
        "datalink": {
          "6802dd58-41e9-4212-b78a-9f02a738ffcb": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": false,
              "orig_num_cols": 4,
              "orig_num_rows": 8,
              "orig_size_bytes": 320,
              "truncated_num_cols": 4,
              "truncated_num_rows": 8,
              "truncated_size_bytes": 320,
              "truncated_string_columns": []
            },
            "display_id": "6802dd58-41e9-4212-b78a-9f02a738ffcb",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-09-02T19:06:31.325630",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_a1eaa92669424c4e83a6504fc9514a4c"
          }
        }
      },
      "outputs": [],
      "source": [
        "training_data[[\"Temperature\", \"Fuel_Price\", \"CPI\", \"Unemployment\"]].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2370c862-40b8-42ba-a1cf-4d6f34fd6f80",
      "metadata": {},
      "source": [
        "Then, we create 4 different scatterplots showing the relationships between each of our predictor variables with the log linear weekly sales:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "808d7cfe-98f5-4583-a3cc-fd4699c738fa",
      "metadata": {
        "tags": [],
        "noteable": {
          "output_collection_id": "f0bb54c8-e38f-404f-908f-695fc1438dae"
        },
        "ExecuteTime": {
          "end_time": "2023-09-02T19:06:32.225242+00:00",
          "start_time": "2023-09-02T19:06:31.490352+00:00"
        }
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize = (9,6))\n",
        "col_names = [\"Temperature\", \"Fuel_Price\", \"CPI\", \"Unemployment\"]\n",
        "\n",
        "for a in range(len(col_names)):\n",
        "    if a < 2:\n",
        "        training_data.plot.scatter(x = col_names[a], y = \"Log_WeeklySales\", ax = axes[0, a])\n",
        "        axes[0, a].set_title(f\"{col_names[a]} vs. Log_WeeklySales\")\n",
        "        m,b = np.polyfit(training_data[col_names[a]], training_data[\"Log_WeeklySales\"], 1)\n",
        "        axes[0, a].plot(training_data[col_names[a]], m*(training_data[col_names[a]]) + b, color = \"yellow\")\n",
        "    else:\n",
        "        training_data.plot.scatter(x = col_names[a], y = \"Log_WeeklySales\", ax = axes[1, a-2])\n",
        "        axes[1, a-2].set_title(f\"{col_names[a]} vs. Log_WeeklySales\")\n",
        "        m,b = np.polyfit(training_data[col_names[a]], training_data[\"Log_WeeklySales\"], 1)\n",
        "        axes[1, a-2].plot(training_data[col_names[a]], m*(training_data[col_names[a]]) + b, color = \"yellow\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56350f98-b1f8-4819-b9fc-a7d0a610b212",
      "metadata": {},
      "source": [
        "From the above plots, we discovered that there is a very weak to no relationship between the predictor variables and response variable. This suggests the variables in use might not be the best predictors of Walmart weekly sales.\n",
        "\n",
        "To understand the relationship between the variables numerically, we have obtained the following correlation matrix using colors to demonstrate the strength of the correlation. By using colors to represent the strength of the correlations, we can easily identify the variables that exhibit significant relationships with each other.\n",
        "\n",
        "This will help us to assess the strength of each variable and determine which ones may be the best predictors of Walmart weekly sales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "14c6be11-6ea2-45b3-bb81-f5f0c6432e0f",
      "metadata": {
        "tags": [],
        "noteable": {
          "output_collection_id": "f17e72a1-0d71-439a-ad2b-6b47606a9005"
        },
        "ExecuteTime": {
          "end_time": "2023-09-02T19:06:32.824062+00:00",
          "start_time": "2023-09-02T19:06:32.385805+00:00"
        }
      },
      "outputs": [],
      "source": [
        "correlation_matrix = round(training_data[[\"Temperature\", \"Fuel_Price\", \"CPI\", \"Unemployment\", \"Log_WeeklySales\"]].corr(), 2)\n",
        "sns.heatmap(correlation_matrix, cmap = \"Blues\", annot = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60a18aee-83ac-4e5d-b81c-abaefa27887e",
      "metadata": {},
      "source": [
        "#### D.3. Performing regression and obtain error statistics:\n",
        "##### __Linear Regression__:\n",
        "- In this subsection, we will be fitting our linear regression model by using all of the explanatory variables as planned. Then, we will calculate the Mean Squared Error to assess the level of accuracy of our model. \n",
        "- The Mean Squared Error is calculated by taking the average of the squared differences between the predicted and actual values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ad62f71b-ffa5-4dfd-ba21-afbb53e79711",
      "metadata": {
        "tags": [],
        "noteable": {
          "output_collection_id": "b87e8a3c-3f87-43ea-a17e-f76153fcb335"
        },
        "ExecuteTime": {
          "end_time": "2023-09-02T19:06:33.453043+00:00",
          "start_time": "2023-09-02T19:06:32.964230+00:00"
        }
      },
      "outputs": [],
      "source": [
        "X_train = training_data[[\"Temperature\", \"Fuel_Price\", \"CPI\", \"Unemployment\", \"Holiday_Flag\"]]\n",
        "y_train = training_data[\"Log_WeeklySales\"]\n",
        "X_test = testing_data[[\"Temperature\", \"Fuel_Price\", \"CPI\", \"Unemployment\", \"Holiday_Flag\"]]\n",
        "y_test = testing_data[\"Log_WeeklySales\"]\n",
        "\n",
        "\n",
        "model = linear_model.LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "mse_train = mean_squared_error(y_train, model.predict(X_train))\n",
        "print(mse_train)\n",
        "mse_test = mean_squared_error(y_test, model.predict(X_test))\n",
        "print(mse_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6afd5459-730c-4f29-8e14-c73c2c44fd3a",
      "metadata": {},
      "source": [
        "- From the statistics reported above, the Mean Squared Error of our linear regression model is roughly 0.334 for training data and 0.329 for testing data. \n",
        "- In the following code, we will be creating a scatterplot between the values our model predicted and the actual values of the dataset. We have also attempted to generate a linear function that best describes the relationship between the predicted and actual values of log weekly Walmart sales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "1e65e5bd-8eaa-45de-87dc-2f7304602f53",
      "metadata": {
        "tags": [],
        "noteable": {
          "output_collection_id": "83ad1e79-c7cd-41fd-84d5-9abd62d75838"
        },
        "ExecuteTime": {
          "end_time": "2023-09-02T19:06:33.813431+00:00",
          "start_time": "2023-09-02T19:06:33.459376+00:00"
        }
      },
      "outputs": [],
      "source": [
        "plt.plot(model.predict(X_test), y_test, \".\")\n",
        "m, b = np.polyfit(model.predict(X_test), y_test, 1)\n",
        "plt.plot(model.predict(X_test), m*model.predict(X_test) + b, color = \"purple\")\n",
        "plt.xlabel(\"Predicted Log Weekly Walmart Sales\")\n",
        "plt.ylabel(\"Actual Log Weekly Walmart Sales\")\n",
        "plt.title(\"Relationship between predicted and actual log weekly Walmart Sales\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10bfb7cc-b523-45c7-b053-9ce3b2d5d5a0",
      "metadata": {},
      "source": [
        "- From this scatterplot, we notice that the actual values and predicted values have a weak positive correlation. Furthermore, we observe that the points on the graph tend to lie on the $y =x$ graph.\n",
        "\n",
        "- We have also calculated the specific correlation coefficient between our predicted and actual Weekly Sales.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0fbd32de-375f-4e7a-aa47-6a354bf54d59",
      "metadata": {
        "tags": [],
        "noteable": {
          "output_collection_id": "3654545c-5174-4596-aa90-c2382a86e5a2"
        },
        "ExecuteTime": {
          "end_time": "2023-09-02T19:06:34.350983+00:00",
          "start_time": "2023-09-02T19:06:34.003071+00:00"
        },
        "datalink": {
          "8186ac7b-e483-4723-8a93-21ae2c69ac0e": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": false,
              "orig_num_cols": 2,
              "orig_num_rows": 2,
              "orig_size_bytes": 48,
              "truncated_num_cols": 2,
              "truncated_num_rows": 2,
              "truncated_size_bytes": 48,
              "truncated_string_columns": []
            },
            "display_id": "8186ac7b-e483-4723-8a93-21ae2c69ac0e",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-09-02T19:06:34.192621",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_24e88eff484648e6ab1ee4124ab7ac9a"
          }
        }
      },
      "outputs": [],
      "source": [
        "dt = pd.DataFrame(model.predict(X_test), y_test)\n",
        "dt.rename(columns = {\"Log_WeeklySales\": \"Actual\",\n",
        "                     0: \"Predicted\"}).reset_index().corr()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4adf98b2-c2d0-4e39-b7e2-265a107c3a3d",
      "metadata": {},
      "source": [
        "- From the correlation matrix shown above, using linear regression, the and predicted values from our model and the actual values of Log Weekly Sales appear to have a positive correlation yet it seems to be weak."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "381755b0-613d-4f14-bf15-c82590ddbfba",
      "metadata": {},
      "source": [
        "##### __LASSO Regression__:\n",
        "- In this part, we attempt to fit the LASSO regression model using the same set of variables as what we did with linear regression. We have also calculated the Lasso coefficients using alpha at a default value of 1.0.\n",
        "- Similarly, to what we did in Linear regression, we will also be reporting our Mean Squared Error of model when operating on both training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3e252b30-1a5b-4450-9414-a5f51af8a1a1",
      "metadata": {
        "tags": [],
        "noteable": {
          "output_collection_id": "b8841c68-c844-49fa-9437-62b6bba7b863"
        },
        "ExecuteTime": {
          "end_time": "2023-09-02T19:06:34.852379+00:00",
          "start_time": "2023-09-02T19:06:34.373457+00:00"
        }
      },
      "outputs": [],
      "source": [
        "la_model = linear_model.Lasso()\n",
        "la_model.fit(X_train, y_train)\n",
        "dt = pd.Series(dict(zip(list(X_train), la_model.coef_)))\n",
        "print(dt)\n",
        "mse_train = mean_squared_error(y_train, la_model.predict(X_train))\n",
        "print(mse_train)\n",
        "mse_test = mean_squared_error(y_test, la_model.predict(X_test))\n",
        "print(mse_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc9a5c3e-a6c7-4d8c-9da6-5713b8f8192d",
      "metadata": {},
      "source": [
        "The Mean Squared Error for our training and testing data are approximately 0.339 and 0.335 respectively.\n",
        "\n",
        "One interesting thing we noticed with our series of Lasso Coefficient is that when alpha is set to be 1.0, `CPI` is the only variable that has a parameter. This somewhat suggests that many of the explanatory variables in use may not have much predicting power.\n",
        "- We have also created another scatterplot to have a glimpse of the relationship between the predicted and actual values of Log Weekly Sales, similarly to the procedure performed in Linear Regression:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f4235614-a569-4bca-a203-77f60eabfd69",
      "metadata": {
        "tags": [],
        "noteable": {
          "output_collection_id": "894d74ad-ebb2-4bc7-a24e-f66e307ec5d4"
        },
        "ExecuteTime": {
          "end_time": "2023-09-02T19:06:35.233520+00:00",
          "start_time": "2023-09-02T19:06:34.858305+00:00"
        }
      },
      "outputs": [],
      "source": [
        "plt.plot(la_model.predict(X_test), y_test, \".\")\n",
        "m,b = np.polyfit(la_model.predict(X_test), y_test, 1)\n",
        "plt.plot(la_model.predict(X_test), m*la_model.predict(X_test) + b, color = \"purple\")\n",
        "plt.xlabel(\"Predicted Log Weekly Walmart Sales\")\n",
        "plt.ylabel(\"Actual Log Weekly Walmart Sales\")\n",
        "plt.title(\"Relationship between predicted and actual log weekly Walmart Sales\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "aa41496f-1b23-49bb-a75c-872aa1ce6709",
      "metadata": {
        "tags": [],
        "noteable": {
          "output_collection_id": "aa364455-bfb3-409a-8f37-65f48ee8aa4d"
        },
        "ExecuteTime": {
          "end_time": "2023-09-02T19:06:35.740133+00:00",
          "start_time": "2023-09-02T19:06:35.382399+00:00"
        },
        "datalink": {
          "f1e16f65-d167-49be-a5c3-0397fdb6cb50": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": false,
              "orig_num_cols": 2,
              "orig_num_rows": 2,
              "orig_size_bytes": 48,
              "truncated_num_cols": 2,
              "truncated_num_rows": 2,
              "truncated_size_bytes": 48,
              "truncated_string_columns": []
            },
            "display_id": "f1e16f65-d167-49be-a5c3-0397fdb6cb50",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-09-02T19:06:35.581886",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_e4efc1d49f87406db518419cbb472aec"
          }
        }
      },
      "outputs": [],
      "source": [
        "dt = pd.DataFrame(la_model.predict(X_test), y_test)\n",
        "dt.rename(columns = {\"Log_WeeklySales\": \"Actual\",\n",
        "                     0: \"Predicted\"}).reset_index().corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37a5c8a1-4236-40ef-ad03-f8373b495bce",
      "metadata": {},
      "source": [
        "- The scatterplot above shows us that the relationship between the two variables is not significant and is a very weak positive relationship."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1fc9228-24d6-4d53-9bb4-cf1cfb5b69fa",
      "metadata": {},
      "source": [
        "##### Random Forest:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c886bde1-c483-458d-889c-349bbd7fbdf5",
      "metadata": {},
      "source": [
        "- In this subsection, we will be fitting a Random Forest model into our training and testing data with a maximum depth of 10 layers. Then, we will report our MSE on our training and testing data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3ea0957e-92cc-4418-93ec-c8bc2e72d4d1",
      "metadata": {
        "tags": [],
        "noteable": {
          "output_collection_id": "94337bfc-84e2-42ff-b4ff-d1f54da1448a"
        },
        "ExecuteTime": {
          "end_time": "2023-09-02T19:06:35.997828+00:00",
          "start_time": "2023-09-02T19:06:35.745792+00:00"
        }
      },
      "outputs": [],
      "source": [
        "rdf = RandomForestRegressor(n_estimators = 10,\n",
        "                           max_depth = 10,\n",
        "                           random_state = 123)\n",
        "rdf.fit(X_train, y_train)\n",
        "mse_train = mean_squared_error(y_train, rdf.predict(X_train))\n",
        "mse_test = mean_squared_error(y_test, rdf.predict(X_test))\n",
        "\n",
        "print(mse_train)\n",
        "print(mse_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2fefff5-532f-4ec4-97ee-4693b3b060de",
      "metadata": {},
      "source": [
        "As observed, our Mean Squared Error for training and testing data using a Random Forest regression model with maximum depth of 10 layers are roughly 0.176 and 0.218 respectively. \n",
        "- Next, we have included a plot showing the relationship between the actual and predict values of Log Weekly Sales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e2bbd2ed-4762-43fa-b29e-32d51aa714ea",
      "metadata": {
        "tags": [],
        "noteable": {
          "output_collection_id": "4f7060a3-f168-4b36-8077-37644f3314b6"
        },
        "ExecuteTime": {
          "end_time": "2023-09-02T19:06:36.414167+00:00",
          "start_time": "2023-09-02T19:06:36.002460+00:00"
        }
      },
      "outputs": [],
      "source": [
        "plt.plot(rdf.predict(X_test), y_test, \".\")\n",
        "m,b = np.polyfit(rdf.predict(X_test), y_test,1) \n",
        "plt.plot(rdf.predict(X_test), m*rdf.predict(X_test)+b, color = \"purple\")\n",
        "plt.xlabel(\"Predicted Log Weekly Walmart Sales\")\n",
        "plt.ylabel(\"Actual Log Weekly Walmart Sales\")\n",
        "plt.title(\"Relationship between predicted and actual log weekly Walmart Sales\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ea8908b7-757e-4a90-b7b5-4ad014032565",
      "metadata": {
        "tags": [],
        "noteable": {
          "output_collection_id": "3cd68bad-2a3e-4206-b654-79a4aa1a9450"
        },
        "ExecuteTime": {
          "end_time": "2023-09-02T19:06:37.017907+00:00",
          "start_time": "2023-09-02T19:06:36.653987+00:00"
        },
        "datalink": {
          "e16111b6-de24-4a6e-a04f-5e3bdad57040": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": false,
              "orig_num_cols": 2,
              "orig_num_rows": 2,
              "orig_size_bytes": 48,
              "truncated_num_cols": 2,
              "truncated_num_rows": 2,
              "truncated_size_bytes": 48,
              "truncated_string_columns": []
            },
            "display_id": "e16111b6-de24-4a6e-a04f-5e3bdad57040",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-09-02T19:06:36.860052",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_81e39f3434a64543bdd50120e4755c8c"
          }
        }
      },
      "outputs": [],
      "source": [
        "dt = pd.DataFrame(rdf.predict(X_test), y_test)\n",
        "dt.rename(columns = {\"Log_WeeklySales\": \"Actual\",\n",
        "                     0: \"Predicted\"}).reset_index().corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "416a34f5-360b-47f0-aa5b-361251da2cdc",
      "metadata": {},
      "source": [
        "### E. Discussions and Observations:\n",
        "- Overall, we have attempted to fit in three different types of models that would help us answer our research question of interest, that is, what is the Weekly Sales at Walmart given several social and economics conditions. The three models we used in our analysis were: multiple linear regression, LASSO regression and random forest.\n",
        "- We notice that the mean squared error (MSE) on training data and testing data (respectively) after using the three models as follow:\n",
        "    * Linear Regression: __0.3342__ and __0.3292__\n",
        "    * LASSO Regression: __0.3394__ and __0.3354__\n",
        "    * Random Forest: __0.1763__ and __0.2179__\n",
        "- Based on our observations at the MSE values, we believe that using the Random Forest model with a maximum layer of 10 will yield the highest level of accuaracy when predicting Walmart weekly sales. Howevever, we suspect that there could be potential problems with our Random Forest model is that it might be overfitting as it produces a higher MSE on testing data compared to the one on training data.\n",
        "- Another point we would like to bring up is that there are many possible ways to evaluate the quality of a regression not just through the Mean Squared Error. In fact, the v\n",
        "- Another concern we encountered while building the regression models is that the relationships between each of our explanatory variable and the response variable tend to be very weak. This indicates that the variables used in our analysis may not be strong predictors of Walmart's weekly sales. To improve the models' predictive power, we suggest introducing more variables that have more predicting power.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78a0367f-4981-4f55-9b5f-687982f51b19",
      "metadata": {},
      "source": [
        "### F. References:\n",
        "- H, M. Y. (2021, December 26). Walmart dataset. Kaggle. \n",
        "    https://www.kaggle.com/datasets/yasserh/walmart-dataset \n",
        "- Lazzari, Z. (2018, August 23). The importance of sales in an organization. Bizfluent.\n",
        "    https://bizfluent.com/the-importance-of-sales-in-an-organization.html "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32aefd0d-15ae-4a38-8887-3fb3ccf75d79",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "selected_hardware_size": "small",
    "kernel_info": {
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}